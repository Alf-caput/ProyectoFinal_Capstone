{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-18T13:08:32.707103Z","iopub.execute_input":"2024-05-18T13:08:32.707506Z","iopub.status.idle":"2024-05-18T13:08:33.850749Z","shell.execute_reply.started":"2024-05-18T13:08:32.707466Z","shell.execute_reply":"2024-05-18T13:08:33.849336Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/stanford-earthquake-dataset-stead/merge.hdf5\n/kaggle/input/stanford-earthquake-dataset-stead/merge.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ninput_dir = '/kaggle/input/stanford-earthquake-dataset-stead/'\nfilename = 'merge.csv'\n\n\ndf = pd.read_csv(os.path.join(input_dir, filename), low_memory=False)\n\n\nimport pandas as pd\nimport numpy as np\nfrom scipy.io import loadmat\n\n# Suponiendo que tienes una columna 'trace_name' con los nombres de archivos\n# y una función que te permite cargar estos archivos, por ejemplo, archivos .mat:\ndef load_seismic_data(filename):\n    # Asume que el archivo .mat contiene una variable 'data' con la señal sísmica\n    data = loadmat(filename)['data']\n    return data\n\ndf['signal'] = df['trace_name'].apply(lambda x: load_seismic_data(input_dir + x))\n\nprint(df.shape)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-18T13:09:58.850509Z","iopub.execute_input":"2024-05-18T13:09:58.850892Z","iopub.status.idle":"2024-05-18T13:10:12.820002Z","shell.execute_reply.started":"2024-05-18T13:09:58.850864Z","shell.execute_reply":"2024-05-18T13:10:12.818607Z"},"trusted":true},"execution_count":4,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Probably \"not found\"\u001b[39;00m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/stanford-earthquake-dataset-stead/109C.TA_201510210555_NO'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     data \u001b[38;5;241m=\u001b[39m loadmat(filename)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m---> 20\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msignal\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrace_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_seismic_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     23\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n","File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","Cell \u001b[0;32mIn[4], line 20\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     17\u001b[0m     data \u001b[38;5;241m=\u001b[39m loadmat(filename)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m---> 20\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msignal\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrace_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mload_seismic_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     23\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n","Cell \u001b[0;32mIn[4], line 17\u001b[0m, in \u001b[0;36mload_seismic_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_seismic_data\u001b[39m(filename):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Asume que el archivo .mat contiene una variable 'data' con la señal sísmica\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:225\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mLoad MATLAB file.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    226\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    227\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m MR\u001b[38;5;241m.\u001b[39mget_variables(variable_names)\n","File \u001b[0;32m/opt/conda/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     f, opened \u001b[38;5;241m=\u001b[39m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m         file_like \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReader needs file name or open file-like object\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     49\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/stanford-earthquake-dataset-stead/109C.TA_201510210555_NO.mat'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/stanford-earthquake-dataset-stead/109C.TA_201510210555_NO.mat'","output_type":"error"}]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2024-05-18T12:43:05.150503Z","iopub.execute_input":"2024-05-18T12:43:05.150843Z","iopub.status.idle":"2024-05-18T12:43:05.158118Z","shell.execute_reply.started":"2024-05-18T12:43:05.150815Z","shell.execute_reply":"2024-05-18T12:43:05.157038Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Index(['network_code', 'receiver_code', 'receiver_type', 'receiver_latitude',\n       'receiver_longitude', 'receiver_elevation_m', 'p_arrival_sample',\n       'p_status', 'p_weight', 'p_travel_sec', 's_arrival_sample', 's_status',\n       's_weight', 'source_id', 'source_origin_time',\n       'source_origin_uncertainty_sec', 'source_latitude', 'source_longitude',\n       'source_error_sec', 'source_gap_deg',\n       'source_horizontal_uncertainty_km', 'source_depth_km',\n       'source_depth_uncertainty_km', 'source_magnitude',\n       'source_magnitude_type', 'source_magnitude_author',\n       'source_mechanism_strike_dip_rake', 'source_distance_deg',\n       'source_distance_km', 'back_azimuth_deg', 'snr_db', 'coda_end_sample',\n       'trace_start_time', 'trace_category', 'trace_name'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-18T12:43:05.160825Z","iopub.execute_input":"2024-05-18T12:43:05.161419Z","iopub.status.idle":"2024-05-18T12:43:05.478506Z","shell.execute_reply.started":"2024-05-18T12:43:05.161381Z","shell.execute_reply":"2024-05-18T12:43:05.477450Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(1265657,)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-18T12:43:05.479645Z","iopub.execute_input":"2024-05-18T12:43:05.479933Z","iopub.status.idle":"2024-05-18T12:43:05.721052Z","shell.execute_reply.started":"2024-05-18T12:43:05.479910Z","shell.execute_reply":"2024-05-18T12:43:05.719987Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                        network_code receiver_code receiver_type  \\\ntrace_name                                                         \n109C.TA_201510210555_NO           TA          109C            HH   \n109C.TA_201511061450_NO           TA          109C            HH   \n109C.TA_201511070220_NO           TA          109C            HH   \n109C.TA_201511140515_NO           TA          109C            HH   \n109C.TA_201512251850_NO           TA          109C            HH   \n\n                         receiver_latitude  receiver_longitude  \\\ntrace_name                                                       \n109C.TA_201510210555_NO            32.8889           -117.1051   \n109C.TA_201511061450_NO            32.8889           -117.1051   \n109C.TA_201511070220_NO            32.8889           -117.1051   \n109C.TA_201511140515_NO            32.8889           -117.1051   \n109C.TA_201512251850_NO            32.8889           -117.1051   \n\n                         receiver_elevation_m  p_arrival_sample p_status  \\\ntrace_name                                                                 \n109C.TA_201510210555_NO                 150.0               NaN      NaN   \n109C.TA_201511061450_NO                 150.0               NaN      NaN   \n109C.TA_201511070220_NO                 150.0               NaN      NaN   \n109C.TA_201511140515_NO                 150.0               NaN      NaN   \n109C.TA_201512251850_NO                 150.0               NaN      NaN   \n\n                         p_weight  p_travel_sec  ...  source_magnitude_type  \\\ntrace_name                                       ...                          \n109C.TA_201510210555_NO       NaN           NaN  ...                    NaN   \n109C.TA_201511061450_NO       NaN           NaN  ...                    NaN   \n109C.TA_201511070220_NO       NaN           NaN  ...                    NaN   \n109C.TA_201511140515_NO       NaN           NaN  ...                    NaN   \n109C.TA_201512251850_NO       NaN           NaN  ...                    NaN   \n\n                        source_magnitude_author  \\\ntrace_name                                        \n109C.TA_201510210555_NO                     NaN   \n109C.TA_201511061450_NO                     NaN   \n109C.TA_201511070220_NO                     NaN   \n109C.TA_201511140515_NO                     NaN   \n109C.TA_201512251850_NO                     NaN   \n\n                         source_mechanism_strike_dip_rake source_distance_deg  \\\ntrace_name                                                                      \n109C.TA_201510210555_NO                               NaN                 NaN   \n109C.TA_201511061450_NO                               NaN                 NaN   \n109C.TA_201511070220_NO                               NaN                 NaN   \n109C.TA_201511140515_NO                               NaN                 NaN   \n109C.TA_201512251850_NO                               NaN                 NaN   \n\n                        source_distance_km  back_azimuth_deg  snr_db  \\\ntrace_name                                                             \n109C.TA_201510210555_NO                NaN               NaN     NaN   \n109C.TA_201511061450_NO                NaN               NaN     NaN   \n109C.TA_201511070220_NO                NaN               NaN     NaN   \n109C.TA_201511140515_NO                NaN               NaN     NaN   \n109C.TA_201512251850_NO                NaN               NaN     NaN   \n\n                         coda_end_sample     trace_start_time  trace_category  \ntrace_name                                                                     \n109C.TA_201510210555_NO              NaN  2015-10-21 05:55:00           noise  \n109C.TA_201511061450_NO              NaN  2015-11-06 14:50:00           noise  \n109C.TA_201511070220_NO              NaN  2015-11-07 02:20:00           noise  \n109C.TA_201511140515_NO              NaN  2015-11-14 05:15:00           noise  \n109C.TA_201512251850_NO              NaN  2015-12-25 18:50:00           noise  \n\n[5 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>network_code</th>\n      <th>receiver_code</th>\n      <th>receiver_type</th>\n      <th>receiver_latitude</th>\n      <th>receiver_longitude</th>\n      <th>receiver_elevation_m</th>\n      <th>p_arrival_sample</th>\n      <th>p_status</th>\n      <th>p_weight</th>\n      <th>p_travel_sec</th>\n      <th>...</th>\n      <th>source_magnitude_type</th>\n      <th>source_magnitude_author</th>\n      <th>source_mechanism_strike_dip_rake</th>\n      <th>source_distance_deg</th>\n      <th>source_distance_km</th>\n      <th>back_azimuth_deg</th>\n      <th>snr_db</th>\n      <th>coda_end_sample</th>\n      <th>trace_start_time</th>\n      <th>trace_category</th>\n    </tr>\n    <tr>\n      <th>trace_name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>109C.TA_201510210555_NO</th>\n      <td>TA</td>\n      <td>109C</td>\n      <td>HH</td>\n      <td>32.8889</td>\n      <td>-117.1051</td>\n      <td>150.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2015-10-21 05:55:00</td>\n      <td>noise</td>\n    </tr>\n    <tr>\n      <th>109C.TA_201511061450_NO</th>\n      <td>TA</td>\n      <td>109C</td>\n      <td>HH</td>\n      <td>32.8889</td>\n      <td>-117.1051</td>\n      <td>150.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2015-11-06 14:50:00</td>\n      <td>noise</td>\n    </tr>\n    <tr>\n      <th>109C.TA_201511070220_NO</th>\n      <td>TA</td>\n      <td>109C</td>\n      <td>HH</td>\n      <td>32.8889</td>\n      <td>-117.1051</td>\n      <td>150.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2015-11-07 02:20:00</td>\n      <td>noise</td>\n    </tr>\n    <tr>\n      <th>109C.TA_201511140515_NO</th>\n      <td>TA</td>\n      <td>109C</td>\n      <td>HH</td>\n      <td>32.8889</td>\n      <td>-117.1051</td>\n      <td>150.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2015-11-14 05:15:00</td>\n      <td>noise</td>\n    </tr>\n    <tr>\n      <th>109C.TA_201512251850_NO</th>\n      <td>TA</td>\n      <td>109C</td>\n      <td>HH</td>\n      <td>32.8889</td>\n      <td>-117.1051</td>\n      <td>150.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2015-12-25 18:50:00</td>\n      <td>noise</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 34 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df.drop(columns=[\"network_code\", \"receiver_code\", \"trace_start_time\"])\nprint(df.shape)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-18T12:43:05.722313Z","iopub.execute_input":"2024-05-18T12:43:05.722649Z","iopub.status.idle":"2024-05-18T12:43:05.962628Z","shell.execute_reply.started":"2024-05-18T12:43:05.722624Z","shell.execute_reply":"2024-05-18T12:43:05.961635Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(1265657, 31)\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                        receiver_type  receiver_latitude  receiver_longitude  \\\ntrace_name                                                                     \n109C.TA_201510210555_NO            HH            32.8889           -117.1051   \n109C.TA_201511061450_NO            HH            32.8889           -117.1051   \n109C.TA_201511070220_NO            HH            32.8889           -117.1051   \n109C.TA_201511140515_NO            HH            32.8889           -117.1051   \n109C.TA_201512251850_NO            HH            32.8889           -117.1051   \n\n                         receiver_elevation_m  p_arrival_sample p_status  \\\ntrace_name                                                                 \n109C.TA_201510210555_NO                 150.0               NaN      NaN   \n109C.TA_201511061450_NO                 150.0               NaN      NaN   \n109C.TA_201511070220_NO                 150.0               NaN      NaN   \n109C.TA_201511140515_NO                 150.0               NaN      NaN   \n109C.TA_201512251850_NO                 150.0               NaN      NaN   \n\n                         p_weight  p_travel_sec  s_arrival_sample s_status  \\\ntrace_name                                                                   \n109C.TA_201510210555_NO       NaN           NaN               NaN      NaN   \n109C.TA_201511061450_NO       NaN           NaN               NaN      NaN   \n109C.TA_201511070220_NO       NaN           NaN               NaN      NaN   \n109C.TA_201511140515_NO       NaN           NaN               NaN      NaN   \n109C.TA_201512251850_NO       NaN           NaN               NaN      NaN   \n\n                         ...  source_magnitude source_magnitude_type  \\\ntrace_name               ...                                           \n109C.TA_201510210555_NO  ...               NaN                   NaN   \n109C.TA_201511061450_NO  ...               NaN                   NaN   \n109C.TA_201511070220_NO  ...               NaN                   NaN   \n109C.TA_201511140515_NO  ...               NaN                   NaN   \n109C.TA_201512251850_NO  ...               NaN                   NaN   \n\n                        source_magnitude_author  \\\ntrace_name                                        \n109C.TA_201510210555_NO                     NaN   \n109C.TA_201511061450_NO                     NaN   \n109C.TA_201511070220_NO                     NaN   \n109C.TA_201511140515_NO                     NaN   \n109C.TA_201512251850_NO                     NaN   \n\n                         source_mechanism_strike_dip_rake  \\\ntrace_name                                                  \n109C.TA_201510210555_NO                               NaN   \n109C.TA_201511061450_NO                               NaN   \n109C.TA_201511070220_NO                               NaN   \n109C.TA_201511140515_NO                               NaN   \n109C.TA_201512251850_NO                               NaN   \n\n                         source_distance_deg  source_distance_km  \\\ntrace_name                                                         \n109C.TA_201510210555_NO                  NaN                 NaN   \n109C.TA_201511061450_NO                  NaN                 NaN   \n109C.TA_201511070220_NO                  NaN                 NaN   \n109C.TA_201511140515_NO                  NaN                 NaN   \n109C.TA_201512251850_NO                  NaN                 NaN   \n\n                         back_azimuth_deg  snr_db  coda_end_sample  \\\ntrace_name                                                           \n109C.TA_201510210555_NO               NaN     NaN              NaN   \n109C.TA_201511061450_NO               NaN     NaN              NaN   \n109C.TA_201511070220_NO               NaN     NaN              NaN   \n109C.TA_201511140515_NO               NaN     NaN              NaN   \n109C.TA_201512251850_NO               NaN     NaN              NaN   \n\n                         trace_category  \ntrace_name                               \n109C.TA_201510210555_NO           noise  \n109C.TA_201511061450_NO           noise  \n109C.TA_201511070220_NO           noise  \n109C.TA_201511140515_NO           noise  \n109C.TA_201512251850_NO           noise  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>receiver_type</th>\n      <th>receiver_latitude</th>\n      <th>receiver_longitude</th>\n      <th>receiver_elevation_m</th>\n      <th>p_arrival_sample</th>\n      <th>p_status</th>\n      <th>p_weight</th>\n      <th>p_travel_sec</th>\n      <th>s_arrival_sample</th>\n      <th>s_status</th>\n      <th>...</th>\n      <th>source_magnitude</th>\n      <th>source_magnitude_type</th>\n      <th>source_magnitude_author</th>\n      <th>source_mechanism_strike_dip_rake</th>\n      <th>source_distance_deg</th>\n      <th>source_distance_km</th>\n      <th>back_azimuth_deg</th>\n      <th>snr_db</th>\n      <th>coda_end_sample</th>\n      <th>trace_category</th>\n    </tr>\n    <tr>\n      <th>trace_name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>109C.TA_201510210555_NO</th>\n      <td>HH</td>\n      <td>32.8889</td>\n      <td>-117.1051</td>\n      <td>150.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>noise</td>\n    </tr>\n    <tr>\n      <th>109C.TA_201511061450_NO</th>\n      <td>HH</td>\n      <td>32.8889</td>\n      <td>-117.1051</td>\n      <td>150.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>noise</td>\n    </tr>\n    <tr>\n      <th>109C.TA_201511070220_NO</th>\n      <td>HH</td>\n      <td>32.8889</td>\n      <td>-117.1051</td>\n      <td>150.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>noise</td>\n    </tr>\n    <tr>\n      <th>109C.TA_201511140515_NO</th>\n      <td>HH</td>\n      <td>32.8889</td>\n      <td>-117.1051</td>\n      <td>150.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>noise</td>\n    </tr>\n    <tr>\n      <th>109C.TA_201512251850_NO</th>\n      <td>HH</td>\n      <td>32.8889</td>\n      <td>-117.1051</td>\n      <td>150.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>noise</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Para trabajar con el conjunto de datos STEAD en un proyecto de Python, especialmente en tareas como la detección de terremotos utilizando aprendizaje automático, es crucial realizar una serie de transformaciones de preprocesamiento y analizar los datos para identificar y mitigar el ruido. Aquí te describo un enfoque general para manejar estos aspectos:\n1. Limpieza y Transformaciones de Datos\n\na. Filtrado de Datos:\n\n    Eliminar registros incompletos: Asegúrate de que todos los registros tengan datos completos para todas las características necesarias.\n    Filtrar por calidad de señal: Puedes necesitar descartar señales con baja relación señal/ruido que podrían ser difíciles de analizar correctamente.\n\nb. Normalización:\n\n    Escalar los datos: Las señales sísmicas pueden necesitar ser normalizadas para tener la misma escala, especialmente útil si estás combinando datos de diferentes estaciones que podrían tener diferentes escalas de medición.\n\nc. Segmentación:\n\n    Ventanas de tiempo: Para análisis temporales, es común segmentar las señales en ventanas de tiempo más cortas que permitan un análisis más detallado y manejable.\n\n2. Análisis de Ruido y Limpieza\n\na. Visualización de Datos:\n\n    Gráficos de tiempo: Realiza gráficos de las señales sísmicas para visualizar la presencia de patrones anormales o ruido excesivo.\n    Espectrogramas: Utiliza transformadas de Fourier para convertir las señales a su representación de frecuencia y observa la distribución de la energía a lo largo de diferentes bandas de frecuencia.\n\nb. Filtrado de Ruido:\n\n    Filtros pasa-banda: Aplica filtros pasa-banda para conservar sólo las frecuencias que son típicamente asociadas con terremotos y descartar otras (como el ruido de alta frecuencia).\n    Filtros adaptativos: Considera el uso de filtros adaptativos si el ruido varía significativamente con el tiempo o entre diferentes registros.\n\n3. Verificación de la Calidad del Dato\n\na. Validación Cruzada:\n\n    Inspección manual: Revisa muestras de señales después de aplicar las transformaciones para asegurarte de que las señales todavía representan eventos sísmicos reales.\n    Comparar con registros conocidos: Verifica si los eventos detectados coinciden con terremotos documentados en otras bases de datos.\n\nb. Uso de métricas de calidad:\n\n    Relación señal/ruido (SNR): Calcula la SNR para estimar la calidad de las señales después del preprocesamiento.\n    Coherencia con registros cercanos: Comprueba si las señales de estaciones cercanas muestran patrones similares, lo que puede indicar la presencia de un verdadero evento sísmico","metadata":{}},{"cell_type":"markdown","source":"Si prefieres un enfoque que no involucre redes neuronales para la detección de terremotos utilizando el conjunto de datos STEAD, puedes considerar métodos de aprendizaje automático tradicionales. Un método eficaz es el uso de Máquinas de Soporte Vectorial (SVM), que son particularmente buenos para clasificación binaria en conjuntos de datos con características de alta dimensión, como las señales sísmicas.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# Normalizar las señales\nscaler = StandardScaler()\nsignals_normalized = scaler.fit_transform(list(df['trace_name']))\n\n# Suponiendo que 'trace_category' indica si la traza es un terremoto o no, por ejemplo\nlabels = (df['trace_category'] == 'earthquake').astype(int).values\n\n# Dividir los datos en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(signals_normalized, labels, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-18T12:51:31.283199Z","iopub.execute_input":"2024-05-18T12:51:31.283600Z","iopub.status.idle":"2024-05-18T12:51:31.363963Z","shell.execute_reply.started":"2024-05-18T12:51:31.283570Z","shell.execute_reply":"2024-05-18T12:51:31.362547Z"},"trusted":true},"execution_count":10,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'trace_name'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Normalizar las señales\u001b[39;00m\n\u001b[1;32m      5\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m----> 6\u001b[0m signals_normalized \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[38;5;28mlist\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrace_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Suponiendo que 'trace_category' indica si la traza es un terremoto o no, por ejemplo\u001b[39;00m\n\u001b[1;32m      9\u001b[0m labels \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrace_category\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mearthquake\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n","\u001b[0;31mKeyError\u001b[0m: 'trace_name'"],"ename":"KeyError","evalue":"'trace_name'","output_type":"error"}]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}